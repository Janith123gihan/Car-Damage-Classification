{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Janith123gihan/Car-Damage-Classification/blob/main/Car_Damage_Classification_Transfer_Learning_EfficientNetB0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsUaIKhkhyJA",
        "outputId": "c7830a4b-4e6c-4856-9649-3a8623401103"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "HsUaIKhkhyJA"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YvopXDqD6ae9"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import load_img\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "from keras.utils import plot_model"
      ],
      "id": "YvopXDqD6ae9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6NCGodc56Hh",
        "outputId": "8483801a-53a1-45ab-859d-10ac832511f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.9.2\n",
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(tf.__version__)\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "id": "h6NCGodc56Hh"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ta-6z74h5-p_"
      },
      "outputs": [],
      "source": [
        "def set_data(train,test, validation ,batchSize, image_size):\n",
        " \n",
        " Image_size = [image_size,image_size]\n",
        "\n",
        " train_datagen= ImageDataGenerator(rotation_range=10,\n",
        "                                   width_shift_range=0.2,\n",
        "                                   height_shift_range=0.2,\n",
        "                                   shear_range=0.2,rescale=1./255,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip=0.5, vertical_flip=0.5\n",
        "                                   )\n",
        "\n",
        " test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        " val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        " #Training dataset\n",
        " train_set = train_datagen.flow_from_directory(\n",
        "                train,\n",
        "                target_size=Image_size,\n",
        "                batch_size=batchSize, \n",
        "                color_mode=\"rgb\",\n",
        "                #shuffle=True,             \n",
        "                interpolation='bicubic',\n",
        "                class_mode='categorical'\n",
        "                )\n",
        " #Testing dataset\n",
        " test_set= test_datagen.flow_from_directory(\n",
        "              test,\n",
        "              target_size=Image_size,\n",
        "              color_mode = \"rgb\", interpolation='bicubic',\n",
        "              class_mode='categorical', shuffle=False\n",
        "             )\n",
        " validation_set = val_datagen.flow_from_directory(\n",
        "    validation, # same directory as training data\n",
        "    target_size=Image_size,\n",
        "    color_mode = \"rgb\",interpolation='bicubic',\n",
        "    batch_size=batchSize)\n",
        " return train_set, test_set, validation_set;"
      ],
      "id": "Ta-6z74h5-p_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UJKLH2uvq8t2"
      },
      "outputs": [],
      "source": [
        "def unfreeze_model(model, num_of_layers):\n",
        "    for layer in model.layers[num_of_layers:]:\n",
        "        if not isinstance(layer, layers.BatchNormalization):\n",
        "            layer.trainable = True\n",
        "    return model"
      ],
      "id": "UJKLH2uvq8t2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "XaPXnPNe9Sp7",
        "outputId": "f5301269-818a-46e0-bfaf-0ed57ed3207d"
      },
      "outputs": [],
      "source": [
        "from keras.layers.pooling.global_average_pooling2d import GlobalAveragePooling2D\n",
        "from tensorflow.keras.applications import VGG16, EfficientNetB1, Xception, EfficientNetB0\n",
        "from tensorflow.keras.layers import AveragePooling2D\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "basemodel = EfficientNetB0(include_top=False, input_shape=(128,128,3), weights=\"imagenet\")\n",
        "# basemodel.summary()\n",
        "basemodel.trainable = False\n",
        "basemodel = unfreeze_model(basemodel, -16)\n",
        "for i, layer in enumerate(basemodel.layers):\n",
        "    print(i, layer.name, layer.trainable)\n",
        "x = basemodel.output\n",
        "x = layers.GlobalAveragePooling2D(name=\"avg_pool\")(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(5, activation=\"softmax\", name=\"pred\")(x)\n",
        "model = tf.keras.Model(basemodel.input, outputs)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "\n",
        "# base_model = VGG16(weights=\"imagenet\", include_top=False, input_tensor=Input(shape = (224,224,3)))  #classification part is removed thatswhy include_top become false\n",
        "\n",
        "# head_model = Model(base_model.input, base_model.layers[-2].output) #last two layers are removed\n",
        "# head_model.trainable = False\n",
        "# head_model = unfreeze_model(head_model,-3)  #last three layers are unfreezed\n",
        "\n",
        "# x = head_model.output\n",
        "# se = layers.GlobalAveragePooling2D(name=\"ch_pool\")(x)\n",
        "# se = layers.Reshape((1,1,512))(se)\n",
        "# se = layers.Dense(32,activation=\"swish\",kernel_initializer='he_normal', use_bias=False)(se)\n",
        "# se = layers.Dense(512,activation=\"sigmoid\",kernel_initializer='he_normal', use_bias=False)(se)\n",
        "# x = layers.Multiply()([se, x])\n",
        "# x = layers.GlobalAveragePooling2D(name=\"avg_pool\")(x)\n",
        "# x = layers.BatchNormalization()(x) #it will normalize values to one - zero\n",
        "# x = layers.Dropout(0.4)(x)\n",
        "# x = layers.Dense(256, activation=\"relu\",kernel_initializer=\"orthogonal\")(x)\n",
        "# x = layers.Dropout(0.3)(x)\n",
        "# x = layers.Dense(128, activation=\"relu\")(x)\n",
        "# x = layers.Dropout(0.3)(x)\n",
        "\n",
        "\n",
        "# outputs = layers.Dense(3, activation=\"softmax\", name=\"pred\")(x)\n",
        "# model = tf.keras.Model(head_model.input, outputs) #model type is created\n",
        "# optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
        "# model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"categorical_accuracy\"])\n",
        "# model.summary()\n",
        "plot_model(model,show_shapes=True, show_layer_names=True)"
      ],
      "id": "XaPXnPNe9Sp7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "be8r_DOPOdot"
      },
      "outputs": [],
      "source": [
        "def plot_hist(hist):\n",
        "    plt.figure(3)\n",
        "    plt.plot(hist.history[\"categorical_accuracy\"])\n",
        "    plt.plot(hist.history[\"val_categorical_accuracy\"])\n",
        "    plt.title(\"model accuracy\")\n",
        "    plt.ylabel(\"accuracy\")\n",
        "    plt.xlabel(\"epoch\")\n",
        "    plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n",
        "    plt.show()\n",
        "    \n",
        "    plt.figure(4)\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'val'], loc='upper left')\n",
        "    plt.show()"
      ],
      "id": "be8r_DOPOdot"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6PpuVyFDv0HT"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, LearningRateScheduler\n",
        "\n",
        "batchSize = 32\n",
        "epoches =80;\n",
        "image_size = 224;\n",
        "train_path = '/content/drive/MyDrive/Car Damage Classification/training'\n",
        "test_path = '/content/drive/MyDrive/Car Damage Classification/testing'\n",
        "validation_path = '/content/drive/MyDrive/Car Damage Classification/validation'\n",
        "\n",
        "# checkpoint_path = \"/content/drive/MyDrive/Car Damage Classification/vgg16/checkpoint.hdf5\"\n",
        "# checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "# cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "#                                                   monitor='val_categorical_accuracy',mode='max',\n",
        "#                                                 save_best_only=True,\n",
        "#                                                 verbose=1)\n",
        "\n",
        "\n",
        "\n",
        "train_set, test_set, validation_set = set_data(train_path,test_path,validation_path, batchSize, image_size)\n",
        "\n",
        "history=model.fit(train_set,  validation_data= validation_set,epochs = epoches, shuffle=True)\n",
        "plot_hist(history)\n"
      ],
      "id": "6PpuVyFDv0HT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VMemO1yyq3Bf"
      },
      "outputs": [],
      "source": [
        "model.save('CNN-Car_Damage_Classification.h5')"
      ],
      "id": "VMemO1yyq3Bf"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5l2oGpAtXWk"
      },
      "source": [
        "# Testing Model"
      ],
      "id": "C5l2oGpAtXWk"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PpNyswT7OpgI"
      },
      "outputs": [],
      "source": [
        "\n",
        "model.save('/content/drive/MyDrive/Car Damage Classification/my_model')\n",
        "results = model.evaluate(test_set,batch_size=32)\n",
        "accuracy = results[1]\n",
        "predict_labels=model.predict(test_set,batch_size=batchSize)\n",
        "test_labels=test_set.classes\n",
        "print(accuracy)\n"
      ],
      "id": "PpNyswT7OpgI"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHAOYrliWEOX"
      },
      "outputs": [],
      "source": [
        "print(test_labels)\n",
        "print(predict_labels.argmax(axis=1))\n",
        "from sklearn.metrics import classification_report\n",
        "print('\\nClassification Report\\n')\n",
        "print(classification_report(test_labels, predict_labels.argmax(axis=1), target_names=['minor', 'moderate', 'severe']))\n",
        "confusion = confusion_matrix(test_labels, predict_labels.argmax(axis=1))\n",
        "print('Confusion Matrix\\n')\n",
        "print(confusion)\n"
      ],
      "id": "sHAOYrliWEOX"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}